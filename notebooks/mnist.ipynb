{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST \n",
    "\n",
    "In this example, we consider the classic machine learning dataset MNIST and the task of classifying handwritten digits. By modern computer vision standards this dataset is considered small, yet it is sufficiently large that many standard classifiers (e.g. those in the Python package `sklearn`) require significant time to train a model. Nonetheless, [Epsilon](http://epopt.io/) is able to fit a model that achieves near state-of-the-art accuracy in a few minutes. \n",
    "\n",
    "<img src=\"mnist.png\" />\n",
    "\n",
    "The standard task is to train a multiclass classifier that can correctly identify digits from their pixel intensity values. For the purposes of this example, we simplify this task slightly and instead consider the binary classification task of even vs. odd. To build our classifier we have a training set of 60K images of dimension 28x28 and a test set of 10K images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine and hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import urllib\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "\n",
    "mnist = np.load(io.BytesIO(urllib.urlopen(\"http://epopt.s3.amazonaws.com/mnist.npz\").read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error(x, y):\n",
    "    return 1 - np.sum(x == y) / float(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to define the hinge loss function in CVXPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_loss(theta, X, y):\n",
    "    return cp.sum_entries(cp.max_elemwise(1 - sp.diags([y],[0])*X*theta, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab384ad1f7db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xf' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "m, n = Xf.shape\n",
    "theta = cp.Variable(n)\n",
    "lam = 10\n",
    "\n",
    "# Form problem with CVXPY and solve with Epsilon\n",
    "f = ep.hinge_loss(theta, Xf, y) + lam*cp.sum_squares(theta)\n",
    "prob = cp.Problem(cp.Minimize(f))\n",
    "ep.solve(prob)\n",
    "\n",
    "# Get solution\n",
    "theta0 = np.ravel(theta.value)\n",
    "print \"Train error:\", error((Xf.dot(theta0)>0)*2-1, y)\n",
    "print \"Test error:\", error((Xtestf.dot(theta0)>0)*2-1, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, Epsilon provides this definition as well as several others, see [`functions.py`](https://github.com/mwytock/epsilon/blob/master/python/epopt/functions.py) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear classifier using random Fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sq_dist(X, Y):\n",
    "    \"\"\"Squared euclidean distance for two sets of points.\"\"\"\n",
    "    return (\n",
    "        np.tile(np.sum(X**2, axis=1), (Y.shape[0],1)).T +\n",
    "        np.tile(np.sum(Y**2, axis=1), (X.shape[0],1)) -\n",
    "        2*X.dot(Y.T))\n",
    "    \n",
    "def median_dist(X):\n",
    "    \"\"\"Compute the approximate median distance by sampling pairs.\"\"\"\n",
    "    k = 3000\n",
    "    idx = np.random.randint(0, X.shape[0], k)\n",
    "    D = sq_dist(X[idx,:], X[idx,:])\n",
    "    return np.sqrt(np.median(D))\n",
    "    \n",
    "def pca(X, dim):\n",
    "    \"\"\"Perform centered PCA.\"\"\"\n",
    "    X = X - X.mean(axis=0)\n",
    "    return LA.eigh(X.T.dot(X))[1][:,-dim:]\n",
    "    \n",
    "def error(x, y):\n",
    "    return 1 - np.sum(x == y) / float(len(x))\n",
    "\n",
    "np.random.seed(0)\n",
    "mnist = np.load(\"/tmp/mnist.npz\")\n",
    "\n",
    "X = mnist[\"X\"]\n",
    "y = (mnist[\"Y\"].ravel() % 2 == 0)*2-1\n",
    "Xtest = mnist[\"Xtest\"]\n",
    "ytest = (mnist[\"Ytest\"][:10000,:].ravel() % 2 == 0)*2-1\n",
    "\n",
    "V = pca(X, 50)\n",
    "Xp = X.dot(V)\n",
    "sigma = median_dist(Xp)\n",
    "\n",
    "n = 4000\n",
    "W = np.random.randn(Xp.shape[1], n) / sigma\n",
    "b = np.random.uniform(0, 2*np.pi, n)\n",
    "X = np.cos(Xp.dot(W) + b)\n",
    "Xtest = np.cos(Xtest.dot(V).dot(W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our transformed dataset, the next step is to fit the classifier. We apply the `hinge_loss()` function discussed above along with some regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "m, n = Xf.shape\n",
    "theta = cp.Variable(n)\n",
    "lam = 10\n",
    "\n",
    "# Form problem with CVXPY and solve with Epsilon\n",
    "f = ep.hinge_loss(theta, Xf, y) + lam*cp.sum_squares(theta)\n",
    "prob = cp.Problem(cp.Minimize(f))\n",
    "ep.solve(prob)\n",
    "\n",
    "# Get solution\n",
    "theta0 = np.ravel(theta.value)\n",
    "print \"Train error:\", error((Xf.dot(theta0)>0)*2-1, y)\n",
    "print \"Test error:\", error((Xtestf.dot(theta0)>0)*2-1, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
